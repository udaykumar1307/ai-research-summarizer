# ğŸ“„ AI Research Summarizer

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![React](https://img.shields.io/badge/React-18.0+-61dafb.svg)
![Hugging Face](https://img.shields.io/badge/HuggingFace-Transformers-yellow.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

An AI-powered research paper and document summarizer using state-of-the-art Hugging Face Transformers (T5, BART, Pegasus) for abstractive text summarization. Upload long documents, research papers, or transcripts and get concise, meaningful summaries instantly.

## ğŸ¯ Key Features

- **Multiple Summarization Models**: T5, BART, Pegasus for different summary styles
- **Abstractive Summarization**: Generates new sentences (not just extraction)
- **Custom Summary Length**: Control summary length (short, medium, long)
- **Multi-format Support**: PDF, TXT, DOCX file uploads
- **Real-time Processing**: Fast inference with optimized transformers
- **Beautiful React UI**: Modern, responsive interface with progress tracking
- **Batch Processing**: Summarize multiple documents at once

## ğŸ—ï¸ Architecture

```
Frontend (React) â†’ Flask API â†’ Hugging Face Transformers â†’ Pre-trained Models (T5/BART)
```

## ğŸ’» Tech Stack

### Backend
- **Python 3.8+**
- **Flask** - RESTful API server
- **Hugging Face Transformers** - Pre-trained NLP models
- **PyTorch** - Deep learning framework
- **PyPDF2** - PDF text extraction
- **python-docx** - DOCX processing

### Frontend
- **React 18** with Hooks
- **Axios** - HTTP client
- **TailwindCSS** - Modern styling
- **Lucide React** - Beautiful icons
- **React Markdown** - Display formatted summaries

## ğŸ“¦ Installation

### Backend Setup

```bash
# Clone the repository
git clone https://github.com/udaykumar1307/ai-research-summarizer.git
cd ai-research-summarizer

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Download models (first run will auto-download)
python download_models.py
```

### Frontend Setup

```bash
cd frontend
npm install
npm start
```

## ğŸš€ Usage

### Start Backend Server
```bash
python app.py
# Server runs on http://localhost:5000
```

### Start Frontend
```bash
cd frontend
npm start
# App runs on http://localhost:3000
```

### Using the Application

1. **Select Model**: Choose between T5, BART, or Pegasus
2. **Upload Document**: PDF, TXT, or DOCX files (up to 10MB)
3. **Set Summary Length**: Short (25%), Medium (50%), or Long (75%)
4. **Generate Summary**: Click "Summarize" and get results in seconds
5. **Download**: Export summary as TXT or PDF

## ğŸ“ Project Structure

```
ai-research-summarizer/
â”œâ”€â”€ app.py                 # Flask backend server
â”œâ”€â”€ summarizer.py          # Summarization logic
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ download_models.py     # Model downloader
â”œâ”€â”€ .env.example          # Environment variables template
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ frontend/
    â”œâ”€â”€ package.json
    â”œâ”€â”€ public/
    â””â”€â”€ src/
        â”œâ”€â”€ App.js        # Main React component
        â”œâ”€â”€ index.js
        â””â”€â”€ App.css
```

## ğŸ”§ API Endpoints

### POST /summarize
Generate summary from uploaded document
- **Request**: `multipart/form-data` with file, model, length
- **Response**: `{"summary": "...", "original_length": 1000, "summary_length": 250}`

### GET /models
Get available summarization models
- **Response**: `{"models": ["t5-base", "facebook/bart-large-cnn", "google/pegasus-xsum"]}`

### GET /health
Health check endpoint
- **Response**: `{"status": "healthy", "models_loaded": true}`

## ğŸ¤– Supported Models

### 1. **T5 (Text-to-Text Transfer Transformer)**
- Best for general-purpose summarization
- Flexible and accurate
- Model: `t5-base`, `t5-small`

### 2. **BART (Facebook)**
- Excellent for news and articles
- Maintains context well
- Model: `facebook/bart-large-cnn`

### 3. **Pegasus (Google)**
- Optimized for research papers
- Best for academic content
- Model: `google/pegasus-xsum`

## ğŸ“ How It Works

1. **Text Extraction**: Extract text from uploaded documents (PDF/DOCX/TXT)
2. **Preprocessing**: Clean and chunk text into manageable segments
3. **Model Selection**: Use selected transformer model (T5/BART/Pegasus)
4. **Tokenization**: Convert text to model-compatible tokens
5. **Inference**: Generate summary using beam search and attention mechanisms
6. **Post-processing**: Clean and format generated summary

## ğŸ“Š Performance Metrics

- **Processing Speed**: 1000 words in ~3-5 seconds
- **Accuracy**: ROUGE-L score of 0.45+ on benchmark datasets
- **Supported Length**: Up to 50,000 words input
- **Summary Quality**: Human-like, coherent abstracts

## ğŸ¤ Use Cases

- Academic research paper summarization
- News article condensation
- Meeting transcripts summarization
- Legal document briefing
- Book chapter summaries
- Technical documentation condensation

## ğŸ”® Future Enhancements

- [ ] Multi-language support (Spanish, French, German)
- [ ] Bullet-point summary format option
- [ ] Key phrase extraction
- [ ] Citation preservation
- [ ] Comparison mode (compare multiple models)
- [ ] API key for programmatic access
- [ ] Chrome extension for webpage summarization

## ğŸ¯ Example Summaries

**Input (500 words)**:
> "Climate change represents one of the most pressing challenges of our time. Recent studies indicate that global temperatures have risen by 1.1Â°C since pre-industrial times..."

**Summary (T5, ~100 words)**:
> "Climate change poses a critical challenge with global temperatures rising 1.1Â°C since pre-industrial times. Scientists emphasize urgent action to limit warming to 1.5Â°C through emissions reduction and renewable energy adoption."

## ğŸ‘¨â€ğŸ’» Author

**Uday Kumar Badugu**
- Email: uday19c61a0401@gmail.com
- Location: Hyderabad, India
- GitHub: [@udaykumar1307](https://github.com/udaykumar1307)

## ğŸ“„ License

MIT License - feel free to use this project for learning and commercial purposes.

## ğŸ™ Acknowledgments

- Hugging Face for pre-trained models
- T5, BART, and Pegasus research teams
- React and Flask communities

---

â­ **Star this repo if you find it helpful!**
